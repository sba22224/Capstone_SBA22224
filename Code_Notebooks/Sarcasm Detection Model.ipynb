{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1fc20b",
   "metadata": {},
   "source": [
    "# Compiling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f915fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e611c52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_no</th>\n",
       "      <th>over_18</th>\n",
       "      <th>use_emojis</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>original_text</th>\n",
       "      <th>class_survey</th>\n",
       "      <th>edited_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>The only thing I got from college was a caffei...</td>\n",
       "      <td>It is sarcastic</td>\n",
       "      <td>The only thing I got from college was a caffei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>@WalesOnline Riveting news.</td>\n",
       "      <td>I don't know</td>\n",
       "      <td>@WalesOnline Riveting news.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>\"My (extended) fam was discussing going on a t...</td>\n",
       "      <td>It is sarcastic</td>\n",
       "      <td>\"My (extended) fam was discussing going on a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>i love shoegaze sm</td>\n",
       "      <td>It is sarcastic</td>\n",
       "      <td>i love shoegaze sm üòÅ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>men are so grimey</td>\n",
       "      <td>It is sarcastic</td>\n",
       "      <td>men are so grimey üò¢</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_no over_18 use_emojis  gender    age   \n",
       "0               1     Yes        Yes  Female  18-24  \\\n",
       "1               1     Yes        Yes  Female  18-24   \n",
       "2               1     Yes        Yes  Female  18-24   \n",
       "3               1     Yes        Yes  Female  18-24   \n",
       "4               1     Yes        Yes  Female  18-24   \n",
       "\n",
       "                                       original_text     class_survey   \n",
       "0  The only thing I got from college was a caffei...  It is sarcastic  \\\n",
       "1                        @WalesOnline Riveting news.     I don't know   \n",
       "2  \"My (extended) fam was discussing going on a t...  It is sarcastic   \n",
       "3                                 i love shoegaze sm  It is sarcastic   \n",
       "4                                  men are so grimey  It is sarcastic   \n",
       "\n",
       "                                         edited_text  \n",
       "0  The only thing I got from college was a caffei...  \n",
       "1                        @WalesOnline Riveting news.  \n",
       "2  \"My (extended) fam was discussing going on a t...  \n",
       "3                               i love shoegaze sm üòÅ  \n",
       "4                                men are so grimey üò¢  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing survey data\n",
    "df_survey = pd.read_excel('survey_results_data.xlsx')\n",
    "df_survey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2bea40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop rows where the response to the survey did not yield a label\n",
    "df_survey = df_survey.drop(df_survey[df_survey['class_survey'] == \"I don't know\"].index)\n",
    "df_survey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25dadbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_survey\n",
       "It is not sarcastic    359\n",
       "It is sarcastic        345\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check distribution of data for each label\n",
    "df_survey[\"class_survey\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e4562bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Avoid bias from qc questions- drop duplicate text prompts and only keep one of each\n",
    "df_survey = df_survey.drop_duplicates(subset=['original_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61161ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of rows with emojis: 63.64%\n"
     ]
    }
   ],
   "source": [
    "#Check the percentage of results that have emojis\n",
    "\n",
    "#Convert non-string values to string format\n",
    "df_survey['edited_text'] = df_survey['edited_text'].astype(str)\n",
    "\n",
    "#Create a regex pattern to match emojis\n",
    "emoji_pattern = re.compile(\"[\\U0001F600-\\U0001F64F\" #Emoticons\n",
    "                           \"\\U0001F300-\\U0001F5FF\"  #Symbols & pictographs\n",
    "                           \"\\U0001F680-\\U0001F6FF\"  #Transport & map symbols\n",
    "                           \"\\U0001F1E0-\\U0001F1FF\"  #Flags\n",
    "                           \"\\U00002702-\\U000027B0\"  #Dingbats\n",
    "                           \"\\U000024C2-\\U0001F251\"  #Enclosed characters\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "#Use the regex pattern to check if the survey outputs have emojis\n",
    "df_survey['has_emoji'] = df_survey['edited_text'].apply(lambda x: bool(re.search(emoji_pattern, x)))\n",
    "\n",
    "#Calculate the percentage of rows that contain emojis\n",
    "percentage_with_emojis = (df_survey[\"has_emoji\"].sum() / len(df_survey)) * 100\n",
    "\n",
    "#Print the result\n",
    "print(f\"Percentage of rows with emojis: {percentage_with_emojis:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f8eb5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_no</th>\n",
       "      <th>over_18</th>\n",
       "      <th>use_emojis</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>original_text</th>\n",
       "      <th>class_survey</th>\n",
       "      <th>edited_text</th>\n",
       "      <th>has_emoji</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>The only thing I got from college was a caffei...</td>\n",
       "      <td>It is sarcastic</td>\n",
       "      <td>The only thing I got from college was a caffei...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>\"My (extended) fam was discussing going on a t...</td>\n",
       "      <td>It is sarcastic</td>\n",
       "      <td>\"My (extended) fam was discussing going on a t...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>i love shoegaze sm</td>\n",
       "      <td>It is sarcastic</td>\n",
       "      <td>i love shoegaze sm üòÅ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>men are so grimey</td>\n",
       "      <td>It is sarcastic</td>\n",
       "      <td>men are so grimey üò¢</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>okay but like the say so song aint that bad. I...</td>\n",
       "      <td>It is sarcastic</td>\n",
       "      <td>okay but like the say so song aint that bad. I...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_no over_18 use_emojis  gender    age   \n",
       "0               1     Yes        Yes  Female  18-24  \\\n",
       "2               1     Yes        Yes  Female  18-24   \n",
       "3               1     Yes        Yes  Female  18-24   \n",
       "4               1     Yes        Yes  Female  18-24   \n",
       "5               1     Yes        Yes  Female  18-24   \n",
       "\n",
       "                                       original_text     class_survey   \n",
       "0  The only thing I got from college was a caffei...  It is sarcastic  \\\n",
       "2  \"My (extended) fam was discussing going on a t...  It is sarcastic   \n",
       "3                                 i love shoegaze sm  It is sarcastic   \n",
       "4                                  men are so grimey  It is sarcastic   \n",
       "5  okay but like the say so song aint that bad. I...  It is sarcastic   \n",
       "\n",
       "                                         edited_text  has_emoji  label  \n",
       "0  The only thing I got from college was a caffei...       True      1  \n",
       "2  \"My (extended) fam was discussing going on a t...       True      1  \n",
       "3                               i love shoegaze sm üòÅ       True      1  \n",
       "4                                men are so grimey üò¢       True      1  \n",
       "5  okay but like the say so song aint that bad. I...       True      1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert labels to 0 and 1 for classification\n",
    "df_survey['label'] = df_survey['class_survey'].replace({'It is sarcastic': 1, 'It is not sarcastic': 0})\n",
    "df_survey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44712cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_no</th>\n",
       "      <th>over_18</th>\n",
       "      <th>use_emojis</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>original_text</th>\n",
       "      <th>class_survey</th>\n",
       "      <th>tweet</th>\n",
       "      <th>has_emoji</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>The only thing I got from college was a caffei...</td>\n",
       "      <td>It is sarcastic</td>\n",
       "      <td>The only thing I got from college was a caffei...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>\"My (extended) fam was discussing going on a t...</td>\n",
       "      <td>It is sarcastic</td>\n",
       "      <td>\"My (extended) fam was discussing going on a t...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>i love shoegaze sm</td>\n",
       "      <td>It is sarcastic</td>\n",
       "      <td>i love shoegaze sm üòÅ</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>men are so grimey</td>\n",
       "      <td>It is sarcastic</td>\n",
       "      <td>men are so grimey üò¢</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>okay but like the say so song aint that bad. I...</td>\n",
       "      <td>It is sarcastic</td>\n",
       "      <td>okay but like the say so song aint that bad. I...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_no over_18 use_emojis  gender    age   \n",
       "0               1     Yes        Yes  Female  18-24  \\\n",
       "2               1     Yes        Yes  Female  18-24   \n",
       "3               1     Yes        Yes  Female  18-24   \n",
       "4               1     Yes        Yes  Female  18-24   \n",
       "5               1     Yes        Yes  Female  18-24   \n",
       "\n",
       "                                       original_text     class_survey   \n",
       "0  The only thing I got from college was a caffei...  It is sarcastic  \\\n",
       "2  \"My (extended) fam was discussing going on a t...  It is sarcastic   \n",
       "3                                 i love shoegaze sm  It is sarcastic   \n",
       "4                                  men are so grimey  It is sarcastic   \n",
       "5  okay but like the say so song aint that bad. I...  It is sarcastic   \n",
       "\n",
       "                                               tweet  has_emoji  label  \n",
       "0  The only thing I got from college was a caffei...       True      1  \n",
       "2  \"My (extended) fam was discussing going on a t...       True      1  \n",
       "3                               i love shoegaze sm üòÅ       True      1  \n",
       "4                                men are so grimey üò¢       True      1  \n",
       "5  okay but like the say so song aint that bad. I...       True      1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename the edited_text column\n",
    "df_survey = df_survey.rename(columns={'edited_text': 'tweet'})\n",
    "df_survey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5050c62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college was a caffei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"My (extended) fam was discussing going on a t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i love shoegaze sm üòÅ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>men are so grimey üò¢</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>okay but like the say so song aint that bad. I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  The only thing I got from college was a caffei...      1\n",
       "2  \"My (extended) fam was discussing going on a t...      1\n",
       "3                               i love shoegaze sm üòÅ      1\n",
       "4                                men are so grimey üò¢      1\n",
       "5  okay but like the say so song aint that bad. I...      1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop all unnecessary columns for the classification task\n",
    "classification_cols = ['tweet', 'label']\n",
    "df = df_survey[classification_cols]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af1902ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>rephrase</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>irony</th>\n",
       "      <th>satire</th>\n",
       "      <th>understatement</th>\n",
       "      <th>overstatement</th>\n",
       "      <th>rhetorical_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>College is really difficult, expensive, tiring...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I do not like when professors don‚Äôt write out ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>I, at the bare minimum, wish companies actuall...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Today my pop-pop told me I was not ‚Äúforced‚Äù to...</td>\n",
       "      <td>1</td>\n",
       "      <td>Today my pop-pop told me I was not \"forced\" to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "      <td>I would say Ted Cruz is an asshole and doesn‚Äôt...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet  sarcastic   \n",
       "0           0  The only thing I got from college is a caffein...          1  \\\n",
       "1           1  I love it when professors draw a big question ...          1   \n",
       "2           2  Remember the hundred emails from companies whe...          1   \n",
       "3           3  Today my pop-pop told me I was not ‚Äúforced‚Äù to...          1   \n",
       "4           4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1   \n",
       "\n",
       "                                            rephrase  sarcasm  irony  satire   \n",
       "0  College is really difficult, expensive, tiring...      0.0    1.0     0.0  \\\n",
       "1  I do not like when professors don‚Äôt write out ...      1.0    0.0     0.0   \n",
       "2  I, at the bare minimum, wish companies actuall...      0.0    1.0     0.0   \n",
       "3  Today my pop-pop told me I was not \"forced\" to...      1.0    0.0     0.0   \n",
       "4  I would say Ted Cruz is an asshole and doesn‚Äôt...      1.0    0.0     0.0   \n",
       "\n",
       "   understatement  overstatement  rhetorical_question  \n",
       "0             0.0            0.0                  0.0  \n",
       "1             0.0            0.0                  0.0  \n",
       "2             0.0            0.0                  0.0  \n",
       "3             0.0            0.0                  0.0  \n",
       "4             0.0            0.0                  0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing iSarcasm dataset\n",
    "df_isarc = pd.read_csv('isarcasm2022.csv')\n",
    "df_isarc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30cf1cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not ‚Äúforced‚Äù to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  The only thing I got from college is a caffein...      1\n",
       "1  I love it when professors draw a big question ...      1\n",
       "2  Remember the hundred emails from companies whe...      1\n",
       "3  Today my pop-pop told me I was not ‚Äúforced‚Äù to...      1\n",
       "4  @VolphanCarol @littlewhitty @mysticalmanatee I...      1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop all unnecessary columns for the classification task\n",
    "classification_cols = ['tweet', 'sarcastic']\n",
    "df_isarc = df_isarc[classification_cols]\n",
    "\n",
    "#Rename the edited_text column\n",
    "df_isarc = df_isarc.rename(columns={'sarcastic': 'label'})\n",
    "\n",
    "#Show transformation\n",
    "df_isarc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a89eea8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    2601\n",
       "1     867\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check distribution of labels\n",
    "df_isarc['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "781486ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3291, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop any tweets from the iSarcasm dataset that were used in the survey as prompts to avoid duplicated entries\n",
    "\n",
    "#Get a list of unique tweets from the survey \n",
    "unique_tweets = df_survey['original_text'].unique()\n",
    "\n",
    "#Remove rows which would give duplicates of text\n",
    "df_isarc = df_isarc[~df_isarc['tweet'].isin(unique_tweets)]\n",
    "\n",
    "#Check distribution of labels\n",
    "df_isarc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a212cbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3995, 2),\n",
       " label\n",
       " 0    2885\n",
       " 1    1110\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the iSarcasm data to the survey data\n",
    "df = pd.concat([df, df_isarc], ignore_index=True)\n",
    "\n",
    "#Check the current quantity and distribution of data\n",
    "df.shape, df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb0af9f",
   "metadata": {},
   "source": [
    "# Checking data augmentation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31dd9e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries \n",
    "import random\n",
    "import nlpaug.augmenter.word as naw\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af8e1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to perform augmentation\n",
    "def augment_text(text):\n",
    "    aug = naw.SynonymAug(aug_src='wordnet')\n",
    "    augmented_text = aug.augment(text)\n",
    "    return augmented_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc04577e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>augmented_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚ÄúOven ready, shove it in the microwave‚Äù and th...</td>\n",
       "      <td>[‚Äú Oven ready, thrust it in the microwave oven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@DarkenerWoW @wochinimen @MissPurplePixie shit...</td>\n",
       "      <td>[@ DarkenerWoW @ wochinimen @ MissPurplePixie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have this reoccurring nightmare where i acci...</td>\n",
       "      <td>[i make this reoccurring incubus where i by ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy Trans Visibility Day all my beautiful, s...</td>\n",
       "      <td>[Happy Trans Visibility Day all my beautiful, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Should I wear my lime green pants?\" dad its 4...</td>\n",
       "      <td>[\" Should Iodin wear my lime light green pants...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text   \n",
       "0  ‚ÄúOven ready, shove it in the microwave‚Äù and th...  \\\n",
       "1  @DarkenerWoW @wochinimen @MissPurplePixie shit...   \n",
       "2  i have this reoccurring nightmare where i acci...   \n",
       "3  Happy Trans Visibility Day all my beautiful, s...   \n",
       "4  \"Should I wear my lime green pants?\" dad its 4...   \n",
       "\n",
       "                                      augmented_text  \n",
       "0  [‚Äú Oven ready, thrust it in the microwave oven...  \n",
       "1  [@ DarkenerWoW @ wochinimen @ MissPurplePixie ...  \n",
       "2  [i make this reoccurring incubus where i by ch...  \n",
       "3  [Happy Trans Visibility Day all my beautiful, ...  \n",
       "4  [\" Should Iodin wear my lime light green pants...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Randomly select 25 rows from the df to check the effects of augmentation\n",
    "random.seed(42)\n",
    "selected_rows = random.sample(range(len(df)), 25)\n",
    "\n",
    "#Create a variable to store results\n",
    "augmented_data = {'original_text': [], 'augmented_text': []}\n",
    "\n",
    "#Augment text sample\n",
    "for row in selected_rows:\n",
    "    original_text = df.loc[row, 'tweet']\n",
    "    augmented_text = augment_text(original_text)\n",
    "    \n",
    "    augmented_data['original_text'].append(original_text)\n",
    "    augmented_data['augmented_text'].append(augmented_text)\n",
    "\n",
    "#Convert to df\n",
    "augmented_df = pd.DataFrame(augmented_data)\n",
    "\n",
    "#Check results\n",
    "augmented_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54efc10c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(has_emoji\n",
       " False    14\n",
       " True     11\n",
       " Name: count, dtype: int64,\n",
       " has_emoji_orig\n",
       " False    14\n",
       " True     11\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if it kept the emojis\n",
    "\n",
    "#Convert non-string values to string format\n",
    "augmented_df['augmented_text'] = augmented_df['augmented_text'].astype(str)\n",
    "augmented_df['original_text'] = augmented_df['original_text'].astype(str)\n",
    "\n",
    "#Use the regex pattern to check if the survey outputs have emojis\n",
    "augmented_df['has_emoji'] = augmented_df['augmented_text'].apply(lambda x: bool(re.search(emoji_pattern, x)))\n",
    "augmented_df['has_emoji_orig'] = augmented_df['original_text'].apply(lambda x: bool(re.search(emoji_pattern, x)))\n",
    "\n",
    "#Check distribution with emojis\n",
    "augmented_df['has_emoji'].value_counts(), augmented_df['has_emoji_orig'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "261d0cb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "‚ÄúOven ready, shove it in the microwave‚Äù and this man is our PM‚úåüèº\n",
      "After:\n",
      "['‚Äú Oven ready, thrust it in the microwave oven ‚Äù and this man follow our PM ‚úå üèº']\n",
      "\n",
      "Before:\n",
      "@DarkenerWoW @wochinimen @MissPurplePixie shit healer\n",
      "After:\n",
      "['@ DarkenerWoW @ wochinimen @ MissPurplePixie shit healer']\n",
      "\n",
      "Before:\n",
      "i have this reoccurring nightmare where i accidentally forget to put on shoes before school and i have to spend the whole day barefoot\n",
      "After:\n",
      "['i make this reoccurring incubus where i by chance forget to put on shoes before school day and i have to spend the whole daytime barefoot']\n",
      "\n",
      "Before:\n",
      "Happy Trans Visibility Day all my beautiful, strong, and sexy trans peeps!! We are unapologetically ourselves üíú\n",
      "After:\n",
      "['Happy Trans Visibility Day all my beautiful, unattackable, and aphrodisiac trans peeps! ! We are unapologetically ourselves üíú']\n",
      "\n",
      "Before:\n",
      "\"Should I wear my lime green pants?\" dad its 4th of july...\n",
      "After:\n",
      "['\" Should Iodin wear my lime light green pants? \" dad its fourth of july. ..']\n",
      "\n",
      "Before:\n",
      "If only people would care as much about poverty and social equality the way they do jumping up and down for Team Remain or Team Leave.\n",
      "After:\n",
      "['If only people would care as much astir impoverishment and social par the elbow room they arrange jumping up and down for Team Remain or Team Leave.']\n",
      "\n",
      "Before:\n",
      "@ThomasCabaret84 @MicrobiomDigest @raoult_didier Surely you‚Äôre not suggesting that their own thorough investigation of their own suspected &lt;fraud&gt; (which found no evidence for said &lt;fraud&gt;) was carried out with anything but the very  highest levels of integrity? Seems completely legit to me‚Ä¶\n",
      "After:\n",
      "['@ ThomasCabaret84 @ MicrobiomDigest @ raoult_didier Surely you ‚Äô re not suggesting that their own thorough investigation of their own suspected & lt; fraud & gt; (which found no evidence for said & lt; fraud & gt;) be carried out with anything simply the very highest levels of integrity? Seems totally legit to me ‚Ä¶']\n",
      "\n",
      "Before:\n",
      "Keanu reeves is killing his role in ozark season 3üòÄ\n",
      "After:\n",
      "['Keanu reeves is kill his part in ozark season trine üòÄ']\n",
      "\n",
      "Before:\n",
      "i love kyungsoo‚Äôs pictures so much they‚Äôre all so pretty i wanna share some with him too now\n",
      "After:\n",
      "['i love kyungsoo ‚Äô s pictures thence much they ‚Äô re all so pretty i wanna portion some with him overly now']\n",
      "\n",
      "Before:\n",
      "\"your pronouns are what's in your pants\" ok. juicy/dumperüòí\n",
      "After:\n",
      "['\" your pronouns be what \\' siemens in your pants \" fine. juicy / dumper üòí']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Manually evaluate results\n",
    "print('Before:')\n",
    "print(augmented_df['original_text'].iloc[0])\n",
    "print('After:')\n",
    "print(augmented_df['augmented_text'].iloc[0])\n",
    "print()\n",
    "print('Before:')\n",
    "print(augmented_df['original_text'].iloc[1])\n",
    "print('After:')\n",
    "print(augmented_df['augmented_text'].iloc[1])\n",
    "print()\n",
    "print('Before:')\n",
    "print(augmented_df['original_text'].iloc[2])\n",
    "print('After:')\n",
    "print(augmented_df['augmented_text'].iloc[2])\n",
    "print()\n",
    "print('Before:')\n",
    "print(augmented_df['original_text'].iloc[3])\n",
    "print('After:')\n",
    "print(augmented_df['augmented_text'].iloc[3])\n",
    "print()\n",
    "print('Before:')\n",
    "print(augmented_df['original_text'].iloc[4])\n",
    "print('After:')\n",
    "print(augmented_df['augmented_text'].iloc[4])\n",
    "print()\n",
    "print('Before:')\n",
    "print(augmented_df['original_text'].iloc[5])\n",
    "print('After:')\n",
    "print(augmented_df['augmented_text'].iloc[5])\n",
    "print()\n",
    "print('Before:')\n",
    "print(augmented_df['original_text'].iloc[6])\n",
    "print('After:')\n",
    "print(augmented_df['augmented_text'].iloc[6])\n",
    "print()\n",
    "print('Before:')\n",
    "print(augmented_df['original_text'].iloc[7])\n",
    "print('After:')\n",
    "print(augmented_df['augmented_text'].iloc[7])\n",
    "print()\n",
    "print('Before:')\n",
    "print(augmented_df['original_text'].iloc[8])\n",
    "print('After:')\n",
    "print(augmented_df['augmented_text'].iloc[8])\n",
    "print()\n",
    "print('Before:')\n",
    "print(augmented_df['original_text'].iloc[9])\n",
    "print('After:')\n",
    "print(augmented_df['augmented_text'].iloc[9])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee43ae2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 72, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 72, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 72, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 72, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 72, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 53, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 53, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 53, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 53, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 53, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 84, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 84, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 84, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 84, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 84, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 62, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 62, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 62, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 62, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 62, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>paraphrased_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My dad just said to me, ‚ÄúHey, you‚Äôre kinda ski...</td>\n",
       "      <td>[My dad just said to me, ‚ÄúHey, you‚Äôre kinda sk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Post university anxiety is creeping in now lik...</td>\n",
       "      <td>[Post university anxiety is creeping in now li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My department is hiring in metaphysics and epi...</td>\n",
       "      <td>[My department is hiring in metaphysics and ep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seeing my friends shine is so heartwarming ü•∫ü•∫</td>\n",
       "      <td>[Seeing my friends shine is so heartwarming ü•∫ü•∫...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If your website still has a google plus share ...</td>\n",
       "      <td>[If your website still has a google plus share...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text   \n",
       "0  My dad just said to me, ‚ÄúHey, you‚Äôre kinda ski...  \\\n",
       "1  Post university anxiety is creeping in now lik...   \n",
       "2  My department is hiring in metaphysics and epi...   \n",
       "3      Seeing my friends shine is so heartwarming ü•∫ü•∫   \n",
       "4  If your website still has a google plus share ...   \n",
       "\n",
       "                                    paraphrased_text  \n",
       "0  [My dad just said to me, ‚ÄúHey, you‚Äôre kinda sk...  \n",
       "1  [Post university anxiety is creeping in now li...  \n",
       "2  [My department is hiring in metaphysics and ep...  \n",
       "3  [Seeing my friends shine is so heartwarming ü•∫ü•∫...  \n",
       "4  [If your website still has a google plus share...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try use of paraphrasing to augment text\n",
    "\n",
    "#Randomly select 25 rows from the df to check the effects of augmentation\n",
    "random.seed(51)\n",
    "selected_rows = random.sample(range(len(df)), 25)\n",
    "\n",
    "#Initialise text generation pipeline with pre-trained model\n",
    "generator = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-1.3B\")\n",
    "\n",
    "#Function to perform text paraphrasing\n",
    "def paraphrase_text(text, num_paraphrase=5):\n",
    "    paraphrased_texts = []\n",
    "    for _ in range(num_paraphrase):\n",
    "        paraphrased_text = generator(text, max_length=200, num_return_sequences=1, do_sample=True)[0][\"generated_text\"]\n",
    "        paraphrased_texts.append(paraphrased_text)\n",
    "    return paraphrased_texts\n",
    "\n",
    "#Create a variable to store results\n",
    "paraphrased_data = {'original_text': [], 'paraphrased_text': []}\n",
    "\n",
    "#Augment text sample\n",
    "for row in selected_rows:\n",
    "    original_text = df.loc[row, 'tweet']\n",
    "    paraphrased_text = paraphrase_text(original_text)\n",
    "    \n",
    "    paraphrased_data['original_text'].append(original_text)\n",
    "    paraphrased_data['paraphrased_text'].append(paraphrased_text)\n",
    "\n",
    "#Convert to df\n",
    "paraphrased_df = pd.DataFrame(paraphrased_data)\n",
    "\n",
    "#Check results\n",
    "paraphrased_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb9516c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(has_emoji\n",
       " False    20\n",
       " True      5\n",
       " Name: count, dtype: int64,\n",
       " has_emoji_orig\n",
       " False    23\n",
       " True      2\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if it kept the emojis\n",
    "\n",
    "#Convert non-string values to string format\n",
    "paraphrased_df['paraphrased_text'] = paraphrased_df['paraphrased_text'].astype(str)\n",
    "paraphrased_df['original_text'] = paraphrased_df['original_text'].astype(str)\n",
    "\n",
    "#Use the regex pattern to check if the survey outputs have emojis\n",
    "paraphrased_df['has_emoji'] = paraphrased_df['paraphrased_text'].apply(lambda x: bool(re.search(emoji_pattern, x)))\n",
    "paraphrased_df['has_emoji_orig'] = paraphrased_df['original_text'].apply(lambda x: bool(re.search(emoji_pattern, x)))\n",
    "\n",
    "#Check distribution with emojis\n",
    "paraphrased_df['has_emoji'].value_counts(), paraphrased_df['has_emoji_orig'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2539f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "My dad just said to me, ‚ÄúHey, you‚Äôre kinda skinny, can you slip behind the fridge to look at something?‚Äù and it might be the nicest compliment I‚Äôve ever gotten. So guys, go tell your girl you think she‚Äôs kinda skinnyü•∞\n",
      "After:\n",
      "['My dad just said to me, ‚ÄúHey, you‚Äôre kinda skinny, can you slip behind the fridge to look at something?‚Äù and it might be the nicest compliment I‚Äôve ever gotten. So guys, go tell your girl you think she‚Äôs kinda skinnyü•∞ (', 'My dad just said to me, ‚ÄúHey, you‚Äôre kinda skinny, can you slip behind the fridge to look at something?‚Äù and it might be the nicest compliment I‚Äôve ever gotten. So guys, go tell your girl you think she‚Äôs kinda skinnyü•∞\\n', 'My dad just said to me, ‚ÄúHey, you‚Äôre kinda skinny, can you slip behind the fridge to look at something?‚Äù and it might be the nicest compliment I‚Äôve ever gotten. So guys, go tell your girl you think she‚Äôs kinda skinnyü•∞ÔøΩ', 'My dad just said to me, ‚ÄúHey, you‚Äôre kinda skinny, can you slip behind the fridge to look at something?‚Äù and it might be the nicest compliment I‚Äôve ever gotten. So guys, go tell your girl you think she‚Äôs kinda skinnyü•∞.', 'My dad just said to me, ‚ÄúHey, you‚Äôre kinda skinny, can you slip behind the fridge to look at something?‚Äù and it might be the nicest compliment I‚Äôve ever gotten. So guys, go tell your girl you think she‚Äôs kinda skinnyü•∞\\n']\n",
      "\n",
      "Before:\n",
      "Post university anxiety is creeping in now like, 1.5 months left out of 5 years üò¨\n",
      "After:\n",
      "['Post university anxiety is creeping in now like, 1.5 months left out of 5 years üò¨\\n\\nSo, let‚Äôs get started‚Ä¶\\n\\nI started using this website, on February 16, 2015, but have used it since', 'Post university anxiety is creeping in now like, 1.5 months left out of 5 years üò¨ I don‚Äôt think I‚Äôve seen a single semester on the anxiety since this year. We‚Äôre all in it together and', 'Post university anxiety is creeping in now like, 1.5 months left out of 5 years üò¨\\n\\nThe past few days have been filled with anxiety in the form of:\\n\\ni am really excited to start university, i can‚Äô', 'Post university anxiety is creeping in now like, 1.5 months left out of 5 years üò¨\\n\\nYou will be getting in the queue for college admission. I have no idea why I‚Äôm doing this, I‚Äôve already', 'Post university anxiety is creeping in now like, 1.5 months left out of 5 years üò¨\\n\\nI had anxiety, I wasn‚Äôt as good as I should‚Äôve been at school, I didn‚Äôt get good']\n",
      "\n",
      "Before:\n",
      "My department is hiring in metaphysics and epistemology (broadly construed). 2-2 teaching load with TA support (2-1 for the first 2 years), MA program, in a city of 260k people with several locations of just about every fast food restaurant. Not bad! https://t.co/bCd3pNEMCa\n",
      "After:\n",
      "['My department is hiring in metaphysics and epistemology (broadly construed). 2-2 teaching load with TA support (2-1 for the first 2 years), MA program, in a city of 260k people with several locations of just about every fast food restaurant. Not bad! https://t.co/bCd3pNEMCa ‚Äî', 'My department is hiring in metaphysics and epistemology (broadly construed). 2-2 teaching load with TA support (2-1 for the first 2 years), MA program, in a city of 260k people with several locations of just about every fast food restaurant. Not bad! https://t.co/bCd3pNEMCa ‚Äî', 'My department is hiring in metaphysics and epistemology (broadly construed). 2-2 teaching load with TA support (2-1 for the first 2 years), MA program, in a city of 260k people with several locations of just about every fast food restaurant. Not bad! https://t.co/bCd3pNEMCa (', 'My department is hiring in metaphysics and epistemology (broadly construed). 2-2 teaching load with TA support (2-1 for the first 2 years), MA program, in a city of 260k people with several locations of just about every fast food restaurant. Not bad! https://t.co/bCd3pNEMCa pic', 'My department is hiring in metaphysics and epistemology (broadly construed). 2-2 teaching load with TA support (2-1 for the first 2 years), MA program, in a city of 260k people with several locations of just about every fast food restaurant. Not bad! https://t.co/bCd3pNEMCa\\n']\n",
      "\n",
      "Before:\n",
      "Seeing my friends shine is so heartwarming ü•∫ü•∫\n",
      "After:\n",
      "['Seeing my friends shine is so heartwarming ü•∫ü•∫\\n\"I have not seen you shine so far, till I behold you!\" -\\n- Sir Ranga Chandra, Raj Ghat, Varanasi, India\\n\\nSunday', 'Seeing my friends shine is so heartwarming ü•∫ü•∫ü•∫\\n\\nüíî @iamsangram.com üéÑüç¶\\U0001f2a3‚ô°', \"Seeing my friends shine is so heartwarming ü•∫ü•∫ü•∫.\\n\\nThe only problem is i've been busy!\\n\\n(And yes, you should see what my bed is made out of:)\\n\\nI\", 'Seeing my friends shine is so heartwarming ü•∫ü•∫ü•∫\\n\\nMy mom loves my friends very much and she keeps encouraging me to get out more and do more. I usually think being more successful in life is easy but', 'Seeing my friends shine is so heartwarming ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫']\n",
      "\n",
      "Before:\n",
      "If your website still has a google plus share button, forgive me if Im not tripping over myself to take your information as credible or current.üò¨\n",
      "After:\n",
      "['If your website still has a google plus share button, forgive me if Im not tripping over myself to take your information as credible or current.üò¨\\nI do also have a blog but unfortunately the pictures that I post don‚Äôt do', 'If your website still has a google plus share button, forgive me if Im not tripping over myself to take your information as credible or current.üò¨\\n\\nSo it seems like your blog still has a share button? I don‚Äôt', 'If your website still has a google plus share button, forgive me if Im not tripping over myself to take your information as credible or current.üò¨\\n\\n partitions: 2\\n\\nPosts:\\n\\n2\\n\\nHi\\n\\nIt is', 'If your website still has a google plus share button, forgive me if Im not tripping over myself to take your information as credible or current.üò¨ However, I will tell you that if you are not using it, you should be, unless', 'If your website still has a google plus share button, forgive me if Im not tripping over myself to take your information as credible or current.üò¨\\n\\nI use to be quite the fan of D&D, but I find it increasingly']\n",
      "\n",
      "Before:\n",
      "2 x sand eating toddlers for sale. No previous owners. DM for details x\n",
      "After:\n",
      "['2 x sand eating toddlers for sale. No previous owners. DM for details x', '2 x sand eating toddlers for sale. No previous owners. DM for details x\\n\\nFinance\\n\\nWe are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking', \"2 x sand eating toddlers for sale. No previous owners. DM for details x. Photos by Michael Anderson for PIXEL CITY, FLORIDA\\n\\nWe've included tons of great photos from across the world, so click on the photos to\", '2 x sand eating toddlers for sale. No previous owners. DM for details x. For more info please email: kim@pumpys.com\\n\\nHi everyone. I have a little kitty from a previous owner, and we are', '2 x sand eating toddlers for sale. No previous owners. DM for details x - [read more]\\n\\n2 x 4ft. girth sand eating toddler for sale. No previous owners. DM for details x - [read more]\\n']\n",
      "\n",
      "Before:\n",
      "@FrankHassleYT Why is his face blurred\n",
      "After:\n",
      "['@FrankHassleYT Why is his face blurred?\\n\\nhttps://twitter.com/Frank_HassleYT/status/803540233900251561\\n\\nFrom the article:\\n\\n‚Äú', \"@FrankHassleYT Why is his face blurred? Does it even matter?\\n\\nA:\\n\\nI'm not sure, but from that pic the man is wearing an Argyll Shire cap - this should put your problem\", \"@FrankHassleYT Why is his face blurred?)\\n\\nI like the idea of a full screen version, but it's not really a big draw either way. A 3:2 aspect ratio would probably work better.\\n\\nI\", '@FrankHassleYT Why is his face blurred? Is it a problem on his end? Or on his ISP? Not really sure. https://bugs.launchpad.net/ubuntu/+source/openoffice.org/+bug/', '@FrankHassleYT Why is his face blurred?\\n\\n[2]']\n",
      "\n",
      "Before:\n",
      "Being 20 years old and going to concerts with my mom means I can scream all the no-no lyrics bc iM aN aDuLt\n",
      "After:\n",
      "['Being 20 years old and going to concerts with my mom means I can scream all the no-no lyrics bc iM aN aDuLtY nEThTsR.\\n\\nI‚Äôm not looking to impress anyone or make the', 'Being 20 years old and going to concerts with my mom means I can scream all the no-no lyrics bc iM aN aDuLt.iS aDtT iCeA.iN mIiS aM a', 'Being 20 years old and going to concerts with my mom means I can scream all the no-no lyrics bc iM aN aDuLtIcE! I live in a world where people say ‚Äúf*ck‚Äù and get', 'Being 20 years old and going to concerts with my mom means I can scream all the no-no lyrics bc iM aN aDuLtR, anYaN aN aN aN aDuLtR. *Gigantic', 'Being 20 years old and going to concerts with my mom means I can scream all the no-no lyrics bc iM aN aDuLtY\\nAnd iM also going to be on the radio and be heard by everyone!\\nI had']\n",
      "\n",
      "Before:\n",
      "@ArenaSwansea @creedfs Specialty starter or light bite featuring laverbread.\n",
      "After:\n",
      "['@ArenaSwansea @creedfs Specialty starter or light bite featuring laverbread. Available in an assortment of flavors, each bottle is infused with the flavors of this signature cheese‚Äîbrie, blue cheese, and truffle.', '@ArenaSwansea @creedfs Specialty starter or light bite featuring laverbread. #hobobob, the ultimate all-around burger! #taste #bistro_mike\\n\\nThis is the special', '@ArenaSwansea @creedfs Specialty starter or light bite featuring laverbread. In a new release you dont have to wait long for this one as theyve introduced one of the nicest light bites yet for the summer!', '@ArenaSwansea @creedfs Specialty starter or light bite featuring laverbread. You can find it for $4. This is a vegan cheese with a crunchy texture that has a hint of sweetness. The texture is similar', '@ArenaSwansea @creedfs Specialty starter or light bite featuring laverbread.\\n\\n#10: Bluebird @cafe mocha mocha @Cafe mocha mocha.\\n\\n#']\n",
      "\n",
      "Before:\n",
      "Every time I see an establishment with paper straws I turn a little bit Republican\n",
      "After:\n",
      "['Every time I see an establishment with paper straws I turn a little bit Republican and I hate the idea of a paper straw.\\n\\nIn politics my conservative leaning is manifested in not having my lawn trimmed on the Fourth of July. And I hate', 'Every time I see an establishment with paper straws I turn a little bit Republican.\\n\\nNow that I‚Äôve gotten this out of my system, it is time I put some words to it. This is exactly what it sounds like:', 'Every time I see an establishment with paper straws I turn a little bit Republican.\" - Ted Cruz, US Senator\\n\\n\"Paper Straws\" (1953)\\n\\n\"Paper Stoppers!\" (1953)\\n\\n\"Paper Straw', 'Every time I see an establishment with paper straws I turn a little bit Republican. So that‚Äôs where I‚Äôm going to start my day. I‚Äôm going to be eating, talking, and writing about the GOP ‚Ä¶', 'Every time I see an establishment with paper straws I turn a little bit Republican.\\n\\nYesterday I decided to give the paper straws a try. They‚Äôre not bad, but the only place where they‚Äôd work is at']\n"
     ]
    }
   ],
   "source": [
    "#Manually evaluate results\n",
    "print('Before:')\n",
    "print(paraphrased_df['original_text'].iloc[0])\n",
    "print('After:')\n",
    "print(paraphrased_df['paraphrased_text'].iloc[0])\n",
    "print()\n",
    "print('Before:')\n",
    "print(paraphrased_df['original_text'].iloc[1])\n",
    "print('After:')\n",
    "print(paraphrased_df['paraphrased_text'].iloc[1])\n",
    "print()\n",
    "print('Before:')\n",
    "print(paraphrased_df['original_text'].iloc[2])\n",
    "print('After:')\n",
    "print(paraphrased_df['paraphrased_text'].iloc[2])\n",
    "print()\n",
    "print('Before:')\n",
    "print(paraphrased_df['original_text'].iloc[3])\n",
    "print('After:')\n",
    "print(paraphrased_df['paraphrased_text'].iloc[3])\n",
    "print()\n",
    "print('Before:')\n",
    "print(paraphrased_df['original_text'].iloc[4])\n",
    "print('After:')\n",
    "print(paraphrased_df['paraphrased_text'].iloc[4])\n",
    "print()\n",
    "print('Before:')\n",
    "print(paraphrased_df['original_text'].iloc[5])\n",
    "print('After:')\n",
    "print(paraphrased_df['paraphrased_text'].iloc[5])\n",
    "print()\n",
    "print('Before:')\n",
    "print(paraphrased_df['original_text'].iloc[6])\n",
    "print('After:')\n",
    "print(paraphrased_df['paraphrased_text'].iloc[6])\n",
    "print()\n",
    "print('Before:')\n",
    "print(paraphrased_df['original_text'].iloc[7])\n",
    "print('After:')\n",
    "print(paraphrased_df['paraphrased_text'].iloc[7])\n",
    "print()\n",
    "print('Before:')\n",
    "print(paraphrased_df['original_text'].iloc[8])\n",
    "print('After:')\n",
    "print(paraphrased_df['paraphrased_text'].iloc[8])\n",
    "print()\n",
    "print('Before:')\n",
    "print(paraphrased_df['original_text'].iloc[9])\n",
    "print('After:')\n",
    "print(paraphrased_df['paraphrased_text'].iloc[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b6d75",
   "metadata": {},
   "source": [
    "# Collect datasets for compilation with current data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5aad6fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sarcasm_ref</th>\n",
       "      <th>human_aggregated</th>\n",
       "      <th>#humans_sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Size on the the Toulouse team, That pack is mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pinball!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So the Scottish Government want people to get ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>villainous pro tip : change the device name on...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would date any of these men ü•∫</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sarcasm_ref   \n",
       "0  Size on the the Toulouse team, That pack is mo...            0  \\\n",
       "1                                           Pinball!            0   \n",
       "2  So the Scottish Government want people to get ...            1   \n",
       "3  villainous pro tip : change the device name on...            0   \n",
       "4                    I would date any of these men ü•∫            0   \n",
       "\n",
       "   human_aggregated  #humans_sarcasm  \n",
       "0                 0                1  \n",
       "1                 0                0  \n",
       "2                 1                4  \n",
       "3                 0                0  \n",
       "4                 0                1  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing SarcEval dataset\n",
    "df_eval = pd.read_csv('english_task_a.csv')\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9d78f453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text  label\n",
       " 0  Size on the the Toulouse team, That pack is mo...      0\n",
       " 1                                           Pinball!      0\n",
       " 2  So the Scottish Government want people to get ...      1\n",
       " 3  villainous pro tip : change the device name on...      0\n",
       " 4                    I would date any of these men ü•∫      0,\n",
       " (1400, 2))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Format for the evaluation\n",
    "\n",
    "#Rename the label column\n",
    "df_eval = df_eval.rename(columns={'sarcasm_ref': 'label'})\n",
    "\n",
    "#Drop all unnecessary columns\n",
    "classification_cols = ['text', 'label']\n",
    "df_eval = df_eval[classification_cols]\n",
    "\n",
    "#Check df format and size\n",
    "df_eval.head(), df_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2f1230fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Be aware  dirty step to get money  #staylight ...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#sarcasm for #people who don't understand #diy...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@IminworkJeremy @medsingle #DailyMail readers ...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@wilw Why do I get the feeling you like games?...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-@TeacherArthurG @rweingarten You probably jus...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets       class\n",
       "0  Be aware  dirty step to get money  #staylight ...  figurative\n",
       "1  #sarcasm for #people who don't understand #diy...  figurative\n",
       "2  @IminworkJeremy @medsingle #DailyMail readers ...  figurative\n",
       "3  @wilw Why do I get the feeling you like games?...  figurative\n",
       "4  -@TeacherArthurG @rweingarten You probably jus...  figurative"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing #sarcasm and #irony dataset\n",
    "df_add = pd.read_csv('train.csv')\n",
    "df_add.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ffdd9e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text  label\n",
       " 0  Be aware  dirty step to get money  #staylight ...      1\n",
       " 1  #sarcasm for #people who don't understand #diy...      1\n",
       " 2  @IminworkJeremy @medsingle #DailyMail readers ...      1\n",
       " 3  @wilw Why do I get the feeling you like games?...      1\n",
       " 4  -@TeacherArthurG @rweingarten You probably jus...      1,\n",
       " (81408, 2))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Format for the evaluation\n",
    "\n",
    "#Rename the label column\n",
    "df_add = df_add.rename(columns={'tweets': 'text'})\n",
    "\n",
    "#All tweets are sarcastic- relabel them all as 1\n",
    "df_add['label'] = 1\n",
    "\n",
    "#Drop all unnecessary columns\n",
    "classification_cols = ['text', 'label']\n",
    "df_add = df_add[classification_cols]\n",
    "\n",
    "#Check df format and size\n",
    "df_add.head(), df_add.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "77ff0b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Be aware  dirty step to get money  #staylight ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for #people who don't understand #diy #artatt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@IminworkJeremy @medsingle #DailyMail readers ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@wilw Why do I get the feeling you like games?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-@TeacherArthurG @rweingarten You probably jus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Be aware  dirty step to get money  #staylight ...      1\n",
       "1   for #people who don't understand #diy #artatt...      1\n",
       "2  @IminworkJeremy @medsingle #DailyMail readers ...      1\n",
       "3    @wilw Why do I get the feeling you like games?       1\n",
       "4  -@TeacherArthurG @rweingarten You probably jus...      1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove specific hashtags from the text\n",
    "df_add['text'] = df_add['text'].str.replace(r'#sarcasm\\b', '', regex=True)\n",
    "df_add['text'] = df_add['text'].str.replace(r'#irony\\b', '', regex=True)\n",
    "df_add['text'] = df_add['text'].str.replace(r'#sarcastic\\b', '', regex=True)\n",
    "\n",
    "#Check transformation\n",
    "df_add.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e58ad512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no one ever predicted this was going to happen...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Stooshie its as closely related as Andrews or...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I find it ironic when Vegans say they love foo...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quick rt that throwing money vine I've not see...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yep, keep adding me to your #devops lists.... ...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets       class\n",
       "0  no one ever predicted this was going to happen...  figurative\n",
       "1  @Stooshie its as closely related as Andrews or...  figurative\n",
       "2  I find it ironic when Vegans say they love foo...  figurative\n",
       "3  Quick rt that throwing money vine I've not see...  figurative\n",
       "4  yep, keep adding me to your #devops lists.... ...  figurative"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Repeat using the test data\n",
    "\n",
    "#Importing #sarcasm and #irony dataset\n",
    "df_add1 = pd.read_csv('test.csv')\n",
    "df_add1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "27e36c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text  label\n",
       " 0  no one ever predicted this was going to happen...      1\n",
       " 1  @Stooshie its as closely related as Andrews or...      1\n",
       " 2  I find it ironic when Vegans say they love foo...      1\n",
       " 3  Quick rt that throwing money vine I've not see...      1\n",
       " 4  yep, keep adding me to your #devops lists.... ...      1,\n",
       " (8128, 2))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Format for the evaluation\n",
    "\n",
    "#Rename the label column\n",
    "df_add1 = df_add1.rename(columns={'tweets': 'text'})\n",
    "\n",
    "#All tweets are sarcastic- relabel them all as 1\n",
    "df_add1['label'] = 1\n",
    "\n",
    "#Drop all unnecessary columns\n",
    "classification_cols = ['text', 'label']\n",
    "df_add1 = df_add1[classification_cols]\n",
    "\n",
    "#Remove specific hashtags from the text\n",
    "df_add1['text'] = df_add1['text'].str.replace(r'#sarcasm\\b', '', regex=True)\n",
    "df_add1['text'] = df_add1['text'].str.replace(r'#irony\\b', '', regex=True)\n",
    "df_add1['text'] = df_add1['text'].str.replace(r'#sarcastic\\b', '', regex=True)\n",
    "\n",
    "#Check df format and size\n",
    "df_add1.head(), df_add1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "02f03bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text  label\n",
       " 0  Be aware  dirty step to get money  #staylight ...      1\n",
       " 1   for #people who don't understand #diy #artatt...      1\n",
       " 2  @IminworkJeremy @medsingle #DailyMail readers ...      1\n",
       " 3    @wilw Why do I get the feeling you like games?       1\n",
       " 4  -@TeacherArthurG @rweingarten You probably jus...      1,\n",
       " (89536, 2))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine the dfs using the same collection strategy\n",
    "df_add = pd.concat([df_add, df_add1], ignore_index=True)\n",
    "\n",
    "#Check df size and form\n",
    "df_add.head(), df_add.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d31e04c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    89536\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check distribution of labels\n",
    "df_add['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48fe0f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TrainSen</td>\n",
       "      <td>0</td>\n",
       "      <td>@0430yes i hope youre lurking rn. i want to li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TrainSen</td>\n",
       "      <td>0</td>\n",
       "      <td>05 really taught me a valuable lesson I'm neve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TrainSen</td>\n",
       "      <td>0</td>\n",
       "      <td>@098BERRY Never had a voice to protest, so you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TrainSen</td>\n",
       "      <td>0</td>\n",
       "      <td>@0hMySt4rs Rest in peace &amp; love to you and you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TrainSen</td>\n",
       "      <td>0</td>\n",
       "      <td>100 days until Christmas! üå≤ #too soon #not rea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Column1  Column2                                            Column3\n",
       "0  TrainSen        0  @0430yes i hope youre lurking rn. i want to li...\n",
       "1  TrainSen        0  05 really taught me a valuable lesson I'm neve...\n",
       "2  TrainSen        0  @098BERRY Never had a voice to protest, so you...\n",
       "3  TrainSen        0  @0hMySt4rs Rest in peace & love to you and you...\n",
       "4  TrainSen        0  100 days until Christmas! üå≤ #too soon #not rea..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specify the file path to read in next dataset- dataset collected and annotated using weak labels -> #not and offensive vocab\n",
    "file_path = 'Train_v1.txt' \n",
    "\n",
    "#Read the data into a df\n",
    "df_add1 = pd.read_csv(file_path, delimiter='\\t', header=None, names=['Column1', 'Column2', 'Column3'])\n",
    "\n",
    "#Check the df\n",
    "df_add1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b406089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text  label\n",
       " 0  @0430yes i hope youre lurking rn. i want to li...      0\n",
       " 1  05 really taught me a valuable lesson I'm neve...      0\n",
       " 2  @098BERRY Never had a voice to protest, so you...      0\n",
       " 3  @0hMySt4rs Rest in peace & love to you and you...      0\n",
       " 4  100 days until Christmas! üå≤ #too soon #not rea...      0,\n",
       " (39780, 2))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename cols based on the contents\n",
    "df_add1 = df_add1.rename(columns={'Column2': 'label'})\n",
    "df_add1 = df_add1.rename(columns={'Column3': 'text'})\n",
    "\n",
    "#Drop unnecessary columns\n",
    "classification_cols = ['text', 'label']\n",
    "df_add1 = df_add1[classification_cols]\n",
    "\n",
    "#Check df form and size\n",
    "df_add1.head(), df_add1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ad357263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text  label\n",
       " 0  I loovee when people text back ... üòí #sarcasti...      1\n",
       " 1  Don't you love it when your parents are Pissed...      1\n",
       " 2      So many useless classes , great to be student      1\n",
       " 3  Oh how I love getting home from work at 3am an...      1\n",
       " 4          I just love having grungy ass hair üòë #not      1,\n",
       " (1975, 2))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset collected and annotated using weak labels -> #not and offensive vocab\n",
    "\n",
    "#Specify the file path to read in next dataset \n",
    "file_path = 'Test_v1.txt' \n",
    "\n",
    "#Read the data into a df\n",
    "df_add2 = pd.read_csv(file_path, delimiter='\\t', header=None, names=['Column1', 'label', 'text'])\n",
    "\n",
    "#Drop unnecessary columns\n",
    "classification_cols = ['text', 'label']\n",
    "df_add2 = df_add2[classification_cols]\n",
    "\n",
    "#Check the df\n",
    "df_add2.head(), df_add2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d7a4cf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text  label\n",
       " 0  @0430yes i hope youre lurking rn. i want to li...      0\n",
       " 1  05 really taught me a valuable lesson I'm neve...      0\n",
       " 2  @098BERRY Never had a voice to protest, so you...      0\n",
       " 3  @0hMySt4rs Rest in peace & love to you and you...      0\n",
       " 4  100 days until Christmas! üå≤ #too soon #not rea...      0,\n",
       " (41755, 2))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine the dfs using the same collection strategy\n",
    "df_add1 = pd.concat([df_add1, df_add2], ignore_index=True)\n",
    "\n",
    "#Check df size and form\n",
    "df_add1.head(), df_add1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8ad83f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    22267\n",
       "1    19488\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check distribution of labels\n",
    "df_add1['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4833a76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text  label\n",
       " 0  Nih min buat fans arsenal @my_supersoccer :D h...      1\n",
       " 1  Give a person power that will be a true test o...      1\n",
       " 2  @LordWilsonVILLA At 21 he looks to have a lot ...      1\n",
       " 3  I'm about to fall asleep and I still have to b...      1\n",
       " 4  I love hearing the shots from the shooting ran...      1,\n",
       " (1368, 2))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset by Riloff\n",
    "\n",
    "#Specify the file path to read in next dataset\n",
    "file_path = 'train.txt' \n",
    "\n",
    "#Read the data into a df\n",
    "df_add2 = pd.read_csv(file_path, delimiter='\\t', header=None, names=['text'])\n",
    "\n",
    "#All tweets are sarcastic- relabel them all as 1\n",
    "df_add2['label'] = 1\n",
    "\n",
    "#Check the df\n",
    "df_add2.head(), df_add2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e798b39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text  label\n",
       " 0  Absolutely love when water is spilt on my phon...      1\n",
       " 1  I was hoping just a LITTLE more shit could hit...      1\n",
       " 2  @pdomo Don't forget that Nick Foles is also th...      1\n",
       " 3  I constantly see tweets about Arsenal on twitt...      1\n",
       " 4  Can feel the feet pulsating...slow one...becau...      1,\n",
       " (588, 2))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Repeat for the train data\n",
    "\n",
    "#Specify the file path to read in next dataset\n",
    "file_path = 'test.txt' \n",
    "\n",
    "#Read the data into a df\n",
    "df_add3 = pd.read_csv(file_path, delimiter='\\t', header=None, names=['text'])\n",
    "\n",
    "#All tweets are sarcastic- relabel them all as 1\n",
    "df_add3['label'] = 1\n",
    "\n",
    "#Check the df\n",
    "df_add3.head(), df_add3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a73164d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text  label\n",
       " 0  Nih min buat fans arsenal @my_supersoccer :D h...      1\n",
       " 1  Give a person power that will be a true test o...      1\n",
       " 2  @LordWilsonVILLA At 21 he looks to have a lot ...      1\n",
       " 3  I'm about to fall asleep and I still have to b...      1\n",
       " 4  I love hearing the shots from the shooting ran...      1,\n",
       " (1956, 2))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine the dfs using the same collection strategy\n",
    "df_add2 = pd.concat([df_add2, df_add3], ignore_index=True)\n",
    "\n",
    "#Check df size and form\n",
    "df_add2.head(), df_add2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "940c939d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1956\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check distribution of labels\n",
    "df_add2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1f9d3358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TrainSen</td>\n",
       "      <td>1</td>\n",
       "      <td>It feels like just a few days ago it was the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TrainSen</td>\n",
       "      <td>1</td>\n",
       "      <td>I love my mom . No matter what we go through ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TrainSen</td>\n",
       "      <td>1</td>\n",
       "      <td>Bump that music ... #imtryingtosleep #sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TrainSen</td>\n",
       "      <td>0</td>\n",
       "      <td>Mexican and black jokes are pretty much the sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TrainSen</td>\n",
       "      <td>0</td>\n",
       "      <td>How to find work you love :</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Column1  Column2                                            Column3\n",
       "0  TrainSen        1  It feels like just a few days ago it was the l...\n",
       "1  TrainSen        1  I love my mom . No matter what we go through ,...\n",
       "2  TrainSen        1      Bump that music ... #imtryingtosleep #sarcasm\n",
       "3  TrainSen        0  Mexican and black jokes are pretty much the sa...\n",
       "4  TrainSen        0                        How to find work you love :"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset by Ghosh- uses weak labelling with #sarcasm\n",
    "\n",
    "#Specify the file path to read in next dataset\n",
    "file_path = 'train (1).txt' \n",
    "\n",
    "#Read the data into a df\n",
    "df_add3 = pd.read_csv(file_path, delimiter='\\t', header=None, names=['Column1', 'Column2', 'Column3'])\n",
    "\n",
    "#Check the df\n",
    "df_add3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cc8aecd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text  label\n",
       " 0  It feels like just a few days ago it was the l...      1\n",
       " 1  I love my mom . No matter what we go through ,...      1\n",
       " 2              Bump that music ... #imtryingtosleep       1\n",
       " 3  Mexican and black jokes are pretty much the sa...      0\n",
       " 4                        How to find work you love :      0,\n",
       " (51189, 2))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename cols based on the contents\n",
    "df_add3 = df_add3.rename(columns={'Column2': 'label'})\n",
    "df_add3 = df_add3.rename(columns={'Column3': 'text'})\n",
    "\n",
    "#Drop unnecessary columns\n",
    "classification_cols = ['text', 'label']\n",
    "df_add3 = df_add3[classification_cols]\n",
    "\n",
    "#Remove weak label\n",
    "df_add3['text'] = df_add3['text'].str.replace(r'#sarcasm\\b', '', regex=True)\n",
    "\n",
    "#Check df form and size\n",
    "df_add3.head(), df_add3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "958d5a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text  label\n",
       " 0  It feels like just a few days ago it was the l...      1\n",
       " 1  I love my mom . No matter what we go through ,...      1\n",
       " 2              Bump that music ... #imtryingtosleep       1\n",
       " 3  Mexican and black jokes are pretty much the sa...      0\n",
       " 4                        How to find work you love :      0,\n",
       " (54877, 2))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Repeat for test data\n",
    "\n",
    "#Specify the file path to read in next dataset\n",
    "file_path = 'test (1).txt' \n",
    "\n",
    "#Read the data into a df\n",
    "df_add4 = pd.read_csv(file_path, delimiter='\\t', header=None, names=['Column1', 'label', 'text'])\n",
    "\n",
    "#Drop unnecessary columns\n",
    "classification_cols = ['text', 'label']\n",
    "df_add4 = df_add4[classification_cols]\n",
    "\n",
    "#Remove weak label\n",
    "df_add4['text'] = df_add4['text'].str.replace(r'#sarcasm\\b', '', regex=True)\n",
    "\n",
    "#Combine the dfs using the same collection strategy\n",
    "df_add3 = pd.concat([df_add3, df_add4], ignore_index=True)\n",
    "\n",
    "#Check df form and size\n",
    "df_add3.head(), df_add3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a19546",
   "metadata": {},
   "source": [
    "# Filter for sarcastic tweets with similar important features to the sarcastic features identified before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7a844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
